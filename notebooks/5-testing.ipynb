{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ebb2f12",
   "metadata": {},
   "source": [
    "# **5 - Testing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b208ed",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58f3d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import joblib\n",
    "import numpy as np\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91357e4",
   "metadata": {},
   "source": [
    "## Predefined variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73489802",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = joblib.load(\"../model/scaler.pkl\")\n",
    "best_model = joblib.load(\"../model/neural_network_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3c05e3",
   "metadata": {},
   "source": [
    "## Define ``predict_sign_language`` function, given the hand landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5762e10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sign_language(hand_landmarks):\n",
    "    landmarks = []\n",
    "    for lm in hand_landmarks.landmark:\n",
    "        landmarks.extend([lm.x, lm.y, lm.z])\n",
    "    \n",
    "    landmarks = np.array(landmarks)\n",
    "    \n",
    "    landmarks_reshaped = landmarks.reshape(1, 21, 3)\n",
    "    \n",
    "\n",
    "    def center_hand(landmarks_batch):\n",
    "        wrist = landmarks_batch[0]  # First landmark is wrist\n",
    "        centered = landmarks_batch - wrist\n",
    "        return centered\n",
    "    \n",
    "    landmarks_centered = center_hand(landmarks_reshaped[0])\n",
    "    \n",
    "\n",
    "    def scale_hand(landmarks_batch):\n",
    "        wrist = landmarks_batch[0]\n",
    "        middle_finger_tip = landmarks_batch[12]\n",
    "        scale = np.linalg.norm(middle_finger_tip - wrist)\n",
    "        \n",
    "        if scale > 0:\n",
    "            scaled = landmarks_batch / scale\n",
    "        else:\n",
    "            scaled = landmarks_batch\n",
    "            \n",
    "        return scaled\n",
    "    \n",
    "    landmarks_scaled = scale_hand(landmarks_centered)\n",
    "    landmarks_flat = landmarks_scaled.flatten()\n",
    "    landmarks_normalized = scaler.transform([landmarks_flat])[0]\n",
    "    \n",
    "    prediction = best_model.predict([landmarks_normalized])[0]\n",
    "    \n",
    "    try:\n",
    "        confidence = np.max(best_model.predict_proba([landmarks_normalized])[0])\n",
    "        return prediction, confidence\n",
    "    except:\n",
    "        return prediction, 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98101e2",
   "metadata": {},
   "source": [
    "## Webcam setup including MediaPipe hands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4183c586",
   "metadata": {},
   "source": [
    "### Initialize MediaPipe hands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52ed89c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bea00f",
   "metadata": {},
   "source": [
    "### Webcam setup check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "983d00c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera detected and ready!\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "if cap.isOpened():\n",
    "    print(\"Camera detected and ready!\")\n",
    "    cap.release()\n",
    "else:\n",
    "    print(\"Camera not found! Please check your webcam connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd26a8e0",
   "metadata": {},
   "source": [
    "## Live webcam detection\n",
    "You can close the camera window by clicking ``Esc`` on your keyboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91768207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection session ended :)\n",
      "Total frames: 929\n",
      "Successful detections: 792\n",
      "Detection rate: 85.3%\n",
      "Detected letters in alphabetical order: A, C, D, E, I, K, M, O, R, S, T, U, V, Y\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "detected_letters = []\n",
    "\n",
    "with mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=1,\n",
    "    min_detection_confidence=0.7,\n",
    "    min_tracking_confidence=0.5\n",
    ") as hands:\n",
    "    frame_count = 0\n",
    "    detection_count = 0\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error reading from camera\")\n",
    "            break\n",
    "            \n",
    "        frame_count += 1\n",
    "        \n",
    "        # Mirror the image horizontally for a selfie-view display\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        h, w, c = frame.shape\n",
    "        \n",
    "        # Convert BGR to RGB for MediaPipe\n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Process the frame for hand detection\n",
    "        results = hands.process(rgb_frame)\n",
    "        \n",
    "        # Default values\n",
    "        prediction = \"\"\n",
    "        confidence = 0.0\n",
    "        \n",
    "        # If hands are detected\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                # Draw hand landmarks\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                \n",
    "                try:\n",
    "                    # Make prediction using our function\n",
    "                    prediction, confidence = predict_sign_language(hand_landmarks)\n",
    "                    detection_count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    prediction = \"ERROR\"\n",
    "                    confidence = 0.0\n",
    "        \n",
    "        # Display prediction on frame\n",
    "        if prediction and prediction != \"ERROR\":\n",
    "            # Main prediction text\n",
    "            color = (0, 255, 0) if confidence > 0.8 else (0, 165, 255) if confidence > 0.6 else (0, 0, 255)\n",
    "            cv2.putText(frame, f\"Letter: {prediction}\", (10, 50),\n",
    "                       cv2.FONT_HERSHEY_DUPLEX, 1.5, color, 3)\n",
    "\n",
    "            if prediction not in detected_letters:\n",
    "                detected_letters.append(prediction)\n",
    "\n",
    "            # Confidence text\n",
    "            cv2.putText(frame, f\"Confidence: {confidence:.2f}\", (10, 90),\n",
    "                       cv2.FONT_HERSHEY_DUPLEX, 0.8, color, 2)\n",
    "        else:\n",
    "            # No detection message\n",
    "            cv2.putText(frame, \"Show your hand clearly\", (10, 50),\n",
    "                       cv2.FONT_HERSHEY_DUPLEX, 1.2, (0, 255, 255), 2)\n",
    "\n",
    "        # Statistics\n",
    "        cv2.putText(frame, f\"Frames: {frame_count} | Detections: {detection_count}\", \n",
    "                   (10, h - 30), cv2.FONT_HERSHEY_DUPLEX, 0.6, (255, 255, 255), 1)\n",
    "\n",
    "        # Instructions\n",
    "        cv2.putText(frame, \"Press ESC to quit\", (10, h - 10),\n",
    "                   cv2.FONT_HERSHEY_DUPLEX, 0.5, (200, 200, 200), 1)\n",
    "\n",
    "        # Show the frame\n",
    "        cv2.imshow(\"Sign Language Alphabet Detection\", frame)\n",
    "        \n",
    "        # Break on ESC key\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # ESC key\n",
    "            break\n",
    "\n",
    "# Cleanup\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Detection session ended :)\")\n",
    "print(f\"Total frames: {frame_count}\")\n",
    "print(f\"Successful detections: {detection_count}\")\n",
    "print(f\"Detection rate: {detection_count/max(frame_count,1)*100:.1f}%\")\n",
    "detected_letters = sorted(set(detected_letters))\n",
    "print(\"Detected letters in alphabetical order: \" + \", \".join(detected_letters))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
